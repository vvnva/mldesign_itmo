# ML System Design: Классификация обращений OTRS

## 1. Цели и предпосылки
### 1.1 Зачем идём в разработку продукта

- **Проблема AS IS**:
  - Оператор вручную читает обращения и выставляет атрибуты (`Тип`, `Общая тема`, `Тематика`, № АЗС и другие атрибуты)
  - Фактический срок первичной маршрутизации: **> 5 дней** при целевом регламенте **1 день для 99% обращений**
  - Высокая нагрузка операторов

- **Цель продукта**:
  - Сократить срок первичной маршрутизации до **1 дня** за счёт автоматизации
  - Снизить нагрузку на операторов и долю рутинной ручной классификации
  - Обеспечить качество маршрутизации, сопоставимое или лучше ручной обработки

### 1.2 Бизнес-требования и ограничения

#### Основные требования

- Автоматическая классификация обращений:
  - **Тип**
  - **Общая тема**
  - **Тематика**
- Побочно — извлечение сущностей:
  - номер АЗС;
  - номер карты лояльности (по диапазонам и маскам)
  - иные структурированные поля при необходимости

#### Качество

- Ошибка классификации по типу/тематике не должна приводить к массовой неверной маршрутизации.
- Приоритет — высокая точность (`Precision`) по классам

По тестовой выборке считаются следующие метрики:
- (`Precisoin`, `Recall`) по отдельным классам
- взвешенный f1 по числу семплов в классах
- средняя взвешенная f-мера с коэффициентом бета от 0.5 до 1 с шагом 0.05:
    - считаем f с бета=0.5 для всех классов, считаем взвешенный f бета
    - считаем f с бета=0.55 для всех классов, считаем взвешенный f бета
    - и так далее до бета=1, после чего считаем среднюю f-меру

- Требования к метрикам (для MVP):
  - средняя f-мера > 0.65

Для NER:
- стандартные метрики:
  - entity-level Precision, Recall, F1 по типам сущностей (АЗС, карты и др.)

#### Технические ограничения

- Источник данных: выгрузки из OTRS в формате `xlsx`
- На этапе MVP — **офлайн-режим**:
  - вход: файл `xlsx` с обращениями;
  - выход: файл `xlsx` с заполненными полями.
- Далее возможно внедрение в инфраструктуру, поэтому:
  - требуется оценка ресурсопотребления модели (GPU, RAM, время инференса на N обращений)

### 1.3 Скоуп итерации (MVP)

#### Входит в скоуп

- Анализ выгрузки за 6 месяцев, выделение паттернов оформления обращений
- Выделение целевого текста обращения:
  - эвристики и регулярные выражения для структурированных паттернов
  - базовая сегментация текста для неструктурированных писем
- Подготовка датасета для обучения:
  - фильтрация обращений без целевого текста;
  - использование только закрытых тикетов с заполненными `Тип`, `Тема`, `Тематика`
- Обучение и оценка моделей для:
  - классификации `(Тип, Тема, Тематика)`;
  - побочной задачи NER (номера АЗС, номера карт лояльности и др)
- Реализация офлайн-пайплайна:
  - чтение `xlsx` → предобработка → инференс → выгрузка `xlsx`.
- Оценка потребляемых ресурсов моделей

#### Не входит в скоуп

- Интеграция в продуктивный контур (онлайн-инференс)
- Разработка полноценного UI для операторов
- Глубокая оптимизация под редкие тематики с малым числом примеров

### 1.4 Предпосылки решения

- Исторические данные доступны в виде выгрузки из OTRS за 6 месяцев:
  - для части обращений легко выделяемые паттерны
  - для половины обращений — неструктурированный текст
- Значительная доля обращений приходится на типичные сценарии:
  - «Удаление аккаунта» (около четверти всех обращений)
  - частые тематики по Программе лояльности и Мобильному приложению
- Наблюдаются шумы:
  - технические заголовки (откуда отправлено, подписи, служебная информация)
  - чисто корпоративные переписки без целевого текста

Эти предпосылки позволяют:
- использовать паттерны и регулярные выражения для выделения целевого текста и сущностей
- применить ML-модели для семантической классификации по «очищенному» тексту

## 2. Методология Data Scientist
### 2.1 Постановка задачи

#### Формальная постановка

- **Дано**:
  - сырой текст обращения `X` с большим количеством шума
  - дополнительные признаки (источник обращения `Способ поступления`, признаки, извлечённые NER)
- **Надо предсказать**:
  - `y_type` - (Тип)
  - `y_topic` (Общая тема)
  - `y_subtopic` (Тематика)

Дополнительная задача:
- по тому же `X` извлечь сущности:
  - `station_id` (№ АЗС)
  - `card_number`

#### Тип задач

- Многоклассовая текстовая классификация (несколько связанных задач)
- Распознавание сущностей (NER)

### 2.2 Блок-схема решения (описание)
Загрузка данных → Определение паттерна → Выделение текста → NER → Классификация → Формирование результата → Оценка ресурсов

Логика системы в терминах шагов пайплайна:

1. **Загрузка данных**
   - Получение выгрузки `xlsx` из OTRS
   - Фильтрация по:
     - статусу «Закрыто»;
     - наличию заполненных целевых полей `Тип`, `Тема`, `Тематика` (для обучения).

2. **Идентификация паттерна обращения**
   - Для каждого обращения определяется паттерн
   - Используются регулярные выражения, шаблоны тем/заголовков

3. **Выделение целевого текста**
   - Для структурированных паттернов:
     - применение эвристик (регулярные выражения, разметка блока «Сообщение» и тп)
   - Для неструктурированных:
     - сегментация текста с удалением технических строк (подписей, цитируемой переписки, хедеров)
     - при отсутствии целевого текста обращение может исключаться из обучающей выборки

4. **Выделение сущностей (NER)**
   - По очищенному тексту:
     - извлечение номеров карт по маскам и диапазонам;
     - извлечение номеров АЗС
   - Результаты могут использоваться:
     - как отдельный выход системы (для маршрутизации)
     - как признаки для классификатора

5. **Модуль классификации**
   - Вход: целевой текст + признаки NER
   - Модели:
     - классификатор `Тип`
     - классификатор `Тема`
     - классификатор `Тематика` (возможна иерархическая схема: сначала `Тема`, затем `Тематика`)
   - Выход: предсказанные значения `Тип`, `Тема`, `Тематика` + вероятности/скор

6. **Формирование результата**
   - Формирование выходного `xlsx`:
     - `Суть обращения`
     - `Способ поступления`;
     - предсказанные `Тип`, `Общая тема`, `Тематика`;
     - № АЗС, № карты

7. **Оценка ресурсов**
   - Замер:
     - времени инференса на N обращений
     - потребления памяти
     - загрузки GPU
   - Подготовка оценки для возможного развёртывания на стороне заказчика


### 2.3 Риски и открытые вопросы

- **Шум и отсутствие целевого текста**:
  - часть обращений не содержит содержательной части (только техническая информация или цепочки переписок)
  - требуется уточнение, можно ли такие обращения системно отбрасывать при формировании выборки.

- **Цепочки пересланных сообщений**:
  - вопрос: как операторы работают с цепочками и как именно проставляются `Тип`, `Тема`, `Тематика` для писем без нового текста

- **Редкие темы и тематики**:
  - малое число примеров может привести к низкой устойчивости классификации

### 2.4 Этапы решения задачи 

Данный раздел сформирован по результатам проведённого EDA на исторических данных OTRS за 6 месяцев в ноутбуках `notebooks\1-1_raw-proc_data-review.ipynb`, `notebooks\1-2_raw-proc_pat-classification.ipynb`

---

### Этап 1. Подготовка данных

#### 1.1 Источники данных и процесс генерации

**Источник данных**:
- Система обработки обращений **OTRS**
- Формат выгрузки: `xlsx`
- Периодичность: выгрузка из OTRS производится регулярно (офлайн)

**Состав данных**:
- Один файл выгрузки содержит:
  - текст обращения
  - метаданные (способ поступления, источник, тема письма и др.)
  - целевые поля, проставленные оператором:
    - `Тип`
    - `Общая тема`
    - `Тематика`

Для обучения используются **только закрытые обращения** с полностью заполненными целевыми полями.

---

#### 1.2 Описание данных и сущностей

**Целевые переменные**:
- `Тип` — верхнеуровневая классификация обращения  
  (Консультация, Заявка, Жалоба, и др.)
- `Общая тема`
- `Тематика` — наиболее детализированный уровень

**Входные данные**:
- Сырой текст обращения (email / форма / мобильное приложение)
- Дополнительные поля:
  - `Способ поступления`
  - извлечённые NER-сущности (№ АЗС, № карты)

**Сущности NER**:
- `station_id` — номер АЗС
- `card_number` — номер карты лояльности
- потенциально: телефон, дата, идентификаторы заказов

---

#### 1.3 Объём и распределение данных

По результатам EDA:
- Всего проанализировано: **~86 000 обращений**
- Выделено **11 паттернов оформления обращений**
- Распределение по паттернам:
  - около **57%** — структурированные или полуавтоматические обращения
  - **43%** — неструктурированные (`Other`)

Наблюдается **сильная несбалансированность классов**:
- Тематика *«Удаление аккаунта»* — около **25% всех обращений**
- Десятки тематик с количеством < 50–100 примеров

---

#### 1.4 Качество данных и выявленные проблемы

Выявленные проблемы:
- **Отсутствие целевого текста**:
  - обращения без содержательной части
  - автоматические уведомления
  - пересланные корпоративные цепочки
- **Шум в тексте**:
  - технические заголовки
  - корпоративные подписи
  - информация об источнике отправки
- **Лейбл-нойз**:
  - одинаковые (`Тип`, `Тема`, `Тематика`) у писем без нового текста
  - возможное наследование темы от предыдущего обращения в цепочке
- **Сильный дисбаланс классов**, особенно на уровне `Тематика`.
  - Тематика Удаление аккаунта покрывает около **25%** всех обращений
  - Существует большое количество тематик с крайне малым числом наблюдений (десятки и единицы примеров)
  - Распределения классов длиннохвостые
- **Иерархическая зависимость целевых переменных**
  - Для каждой `Общей темы` наблюдается почти уникальный набор `Тематик`.
  - Это позволяет выдвинуть гипотезу иерархической классификации:
    - сначала `Общая тема`,
    - затем `Тематика` внутри предсказанной темы
  - Переменная `Тип` при этом слабо связана с иерархией и рассматривается как отдельная задача классификации

---

#### 1.5 Работа с недостаточностью и дисбалансом данных

Рассматриваемые стратегии:
- отбрасывание тематик с экстремально малым числом примеров (ниже порога)
- агрегация редких тематик в категорию `Other`
- генерация синтетических примеров (data augmentation) для текстов
- использование иерархической классификации для снижения сложности задачи

---
#### 1.6 Конфиденциальность данных

В текстах обращений потенциально присутствуют:
- номера карт лояльности
- номера телефонов
- персональные данные клиентов

Меры обработки:
- извлечение чувствительных данных через NER
- исключение их из входов ML-моделей
- хранение обезличенных текстов для обучения

---
#### 1.7 Результат этапа

На выходе этапа:
- очищенный и размеченный датасет:
  - `target_text`
  - `Тип`, `Тема`, `Тематика`
  - NER-признаки;
- описание паттернов обращений;
- Зафиксированные правила фильтрации и исключения данных

---

### Этап 2. Подготовка прогнозных моделей

#### 2.1 ML-метрики и функции потерь

**Для классификации**:
- Основная метрика:  
  Weighted beta-F1, усреднённая по β ∈ [0.5; 1] с шагом 0.05.
- Другие метрики:
  - Weighted Presicion
  - Weighted Recall
  - Weighted F1

- Приоритет: высокий `Precision` для минимизации ошибок маршрутизации
- Функции потерь: Cross-Entropy с весами классов.




**Для NER**:
- Уровень 1:
  - entity-level Precision / Recall / F1
- Уровень 2 (постобработка):
  - Precision / Recall / F1 по корректно извлечённым значениям сущностей.
  - Метрики считаются по тем же формулировкам (precision/recall/F1), но теперь сравниваются именно извлечённые строки значений после постобработки
---

#### 2.2 Схема валидации

- Разделение данных:
  - train / validation / test
- Стратификация по:
  - `Тип`
  - `Тема`
- Дополнительно:
  - контроль распределения паттернов между выборками.
- Валидация проводится **офлайн**, без временного leakage.


#### 2.2 Схема валидации

- Разделение данных:
  - train / validation / test.
- Контроль репрезентативности:
  - сохранение распределений по `Общей теме`
  - исключение утечек между цепочками писем
  - сохранение распределений по паттернам

---

#### 2.3 Бейзлайн
**Гипотеза бейзлайна**
- Сначала предсказывается `Общая тема`
- Затем `Тематика` внутри предсказанной темы
- `Тип` — отдельный классификатор

**Архитектура**
- Языковой эмбеддер (Sentence-BERT / RuBERT)
- Классический классификатор (LogReg / LightGBM / CatBoost)
- Вход: эмбеддинг целевого текста + простые признаки

**Цель бейзлайна**
- Проверка реализуемости задачи
- Получение нижней границы качества
- Валидация гипотезы иерархической структуры
---

#### 2.4 MVP-модели

**Классификация**:
- Transformer-based модели (BERT-like)
- Возможна иерархическая схема:
  - сначала `Тема`, затем `Тематика`
- Использование:
  - `target_text`
  - NER-признаков как дополнительных фичей

**NER**:
- Sequence labeling модель
- Дообучение на:
  - реальной разметке
  - синтетически сгенерированных данных

---

#### 2.5 Анализ и интерпретация

- Анализ ошибок по:
  - паттернам
  - редким тематикам
  - типам источников
- Интерпретация:
  - confusion matrix
  - примеры ошибок маршрутизации
- Согласование качества с бизнес-заказчиком

---

#### 2.6 Риски этапа и их снижение

| Риск | Митигирующие меры |
|----|------------------|
| Малые классы | Агрегация, синтетика |
| Отсутствие текста | Фильтрация, fallback |
| Шум | Улучшение сегментации |
| Смещение разметки | Анализ ошибок операторов |

---

#### 2.7 Результат этапа
- Реализованный бейзлайн
- Обученные модели:
  - классификации
  - NER
- Зафиксированные метрики качества
- Рекомендации по финальной архитектуре MVP 

---

### Этап 3. Постобработка и бизнес-правила

- Обработка случаев:
  - низкая уверенность модели
  - отсутствие целевого текста
- Интеграция бизнес-правил:
  - ручная маршрутизация при low confidence
  - fallback-логика

---

### Этап 4. Офлайн-инференс и оценка ресурсов

- Реализация пайплайна:
  - `xlsx → preprocessing → inference → xlsx`
- Оценка:
  - времени обработки N обращений
  - RAM / GPU
  - масштабируемости решения

---

### Этап 5. NER и постобработка сущностей
- Извлечение АЗС, карт и др
- Очистка, постобработка и нормализация значений
- Использование как бизнес-выхода и признаков

## 3. Подготовка пилота

Пилот нацелен на проверку применимости решения в реальном процессе первичной маршрутизации обращений:
- качество автоклассификации (`Тип`, `Общая тема`, `Тематика`) и извлечения сущностей (NER)
- снижение времени на первичную маршрутизацию и доли ручной рутины
- вычислительная реализуемость (время инференса, потребление памяти) в условиях офлайн-контура

---

### 3.1. Способ оценки пилота

#### Дизайн пилота

**Формат:** офлайн / shadow-mode (без влияния на реальную маршрутизацию на первом шаге) 
**Вход:** выгрузка `xlsx` с новыми обращениями за период пилота  
**Выход:** `xlsx` с предсказанными полями:
- `Тип`, `Общая тема`, `Тематика` + score/вероятность
- извлечённые сущности (АЗС, карта, ТРК, fuel и пр.) в “очищенном” виде (postprocess-level)

**Блоки решения в пилоте**
1) **Сегментация / выделение целевого текста** (эвристики + правила по паттернам).=  
2) **NER**: модель токен-классификации + постобработка значений сущностей (clean spans)
3) **Классификация**:
   - Бейзлайн: эмбеддер → LogisticRegression
     - отдельная модель для `Тип`;
     - отдельная модель для `Общей темы`;
     - набор моделей `Тематика` внутри каждой `Общей темы` (иерархическая схема)

#### Как собираем ground truth

**Источник истины:** разметка операторов по итогам обработки обращений (поля `Тип/Тема/Тематика` после закрытия/финализации)
Пилот оценивается на:
- обращениях, которые появились *после* обучения моделей и не использовались в обучающих сплитах

#### Сэмплинг пилотных данных

- Основной вариант: ежедневные/еженедельные выгрузки за период пилота.
- Для корректной оценки качества по ключевым классам:
  - обязательная доля обращений из топ-`N` тем/тематик
  - контрольная выборка “длинного хвоста” (редкие тематики)
  - стратификация по `Общей теме` и по источнику (`Способ поступления`), т.к. структура текста отличается

#### Способ сравнения

- Сравнение **предсказаний модели** с **финальной разметкой операторов**.
- Отдельно считаем качество:
  - для каждого целевого поля (`Тип`, `Общая тема`, `Тематика`)
  - по крупным классам (top-10/20) и по “хвосту”
  - по паттернам обращений (структурированные vs `Other`)

---

### 3.2. Что считаем успешным пилотом

#### Метрики качества

**Классификация**
- Целевая агрегированная метрика: **Weighted beta-F1** (усреднение β∈[0.5..1] с шагом 0.05).
- Дополнительно:
  - weighted F1;
  - precision по ключевым классам (приоритет качества маршрутизации)

**Критерии успеха пилота (MVP)**
- `Weighted beta-F1` ≥ **0.65** на пилотной выборке по каждому из полей:
  - `Тип`;
  - `Общая тема`;
  - `Тематика` (для иерархии — итоговое качество поля)

**NER**
- Уровень 1 (entity-level): Precision / Recall / F1 по сущностям (`azs`, `card`, `trk`, `fuel`).
- Уровень 2 (postprocess-level): Precision / Recall / F1 по “очищенным” значениям сущностей (строковое совпадение после нормализации)
- Успех MVP по NER:
  - entity-level F1 ≥ 0.80 на ключевых сущностях (`azs`, `card`)
  - postprocess-level F1 ≥ 0.85 на ключевых сущностях (`azs`, `card`)

#### Метрики бизнес-эффекта (в пилоте)

Поскольку первый пилот — shadow-mode, бизнес-эффект измеряем прокси-метриками:
- **доля обращений**, где модель уверенно заполнила все поля (`Тип/Тема/Тематика`) и прошла пороги уверенности
- оценка потенциальной экономии времени операторов (опрос + выборочный “тайминг”)
- доля обращений, где извлечены ключевые сущности (АЗС, карта) с высоким качеством

---

### 3.3. Подготовка пилота

#### Вычислительные ограничения и план оценки вычислительной сложности

Пилот проводится в офлайн-режиме, поэтому ключевые нефункциональные требования:
- обработка выгрузки обращений должна укладываться в допустимое временное окно
- решение должно быть воспроизводимым на ограниченных ресурсах (CPU-only или 1 GPU)
- время инференса и потребление памяти должны быть измеримы и контролируемы

##### Бюджет вычислений (MVP / пилот)
На пилоте закладываем 2 профиля окружения:

1) **CPU-only профиль (минимально допустимый)**
- 8–16 vCPU
- 32–64 GB RAM
- без GPU
- цель: обеспечить работоспособность пайплайна и приемлемое время на дневную выгрузку

2) **GPU-профиль (ускоренный)**
- 1× GPU уровня T4/A10 (или эквивалент)
- 16–24 GB VRAM
- цель: ускорение инференса NER и эмбеддингов

Ограничение по времени для пилота:
- обработка **N = 10 000 обращений** должна занимать не более **1 часа** (целевой ориентир для MVP)

#### Подготовительные шаги

1) **Зафиксировать пайплайн данных и правила фильтрации**
   - какие паттерны не используем для обучения
   - что считаем “целевым текстом”
   - как обрабатываем обращения без целевого текста (skip / fallback / отправка на ручную обработку)

2) **Определить режим выдачи предсказаний**
   - Предсказываем всегда, но:
     - если уверенность ниже порога → ставим флаг `needs_review=1` и не предлагаем авто-маршрутизацию
     - для NER применяем пороги по сущностям (thresholding)

3) **Подготовить инфраструктуру офлайн-инференса**
   - скрипт/ноутбук/CLI:
     - `input.xlsx → preprocess → NER → classification → output.xlsx`
   - логирование:
     - время инференса, ошибки, доля пустых/отфильтрованных обращений

#### Риски пилота и как их снимаем

- **Смещение данных во времени / новые тематики** -> мониторинг “unknown/other”, периодический дообучающий цикл
- **Обращения без целевого текста** -> отдельный класс/флаг + обязательная ручная обработка
- **Длинный хвост тематик** -> агрегация редких классов или снижение детализации на MVP
- **Ошибки высокой цены** (массовая неверная маршрутизация) -> режим с порогами уверенности + human-in-the-loop
